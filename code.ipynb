{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relevant-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coastal-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [(1, 0), (4, 1), (5, 2), (6, 3), (7, 4), (12, 5), (13, 6), (14, 7), (19, 8)]\n",
    "for z, c in idx:\n",
    "    data_set = pickle.load(open(r'label' + str(z) + '\\goal_set.p', 'rb'))\n",
    "    data = data_set['train'] + data_set['test'] + data_set['validate']\n",
    "    dis_s = {}\n",
    "    symptoms = {}\n",
    "    for xy in data:\n",
    "        disease = xy['disease_tag']\n",
    "        dis_s.setdefault(disease, {'index':len(dis_s), 'symptom':dict()})\n",
    "        temp2 = xy['goal']['implicit_inform_slots']\n",
    "        temp2.update(xy['goal']['explicit_inform_slots'])\n",
    "        for x, y in temp2.items():\n",
    "            symptoms.setdefault(x, len(symptoms))\n",
    "            dis_s[disease]['symptom'].setdefault(x, 0)\n",
    "            dis_s[disease]['symptom'][x] += 1\n",
    "    #for x in dis_s:\n",
    "        #frequency = 0\n",
    "        #for y in dis_s[x]['symptom']:\n",
    "            #frequency += dis_s[x]['symptom'][y]\n",
    "        #for y in dis_s[x]['symptom']:\n",
    "            #dis_s[x]['symptom'][y] /= frequency\n",
    "    symptoms['Total Symptom'] = len(symptoms)\n",
    "    pickle.dump(obj = dis_s, file = open(r'label' + str(z) + '\\out1.p', 'wb'), protocol = 2)\n",
    "    pickle.dump(obj = symptoms, file = open(r'label' + str(z) + '\\out2.p', 'wb'), protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stupid-israel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "52\n",
      "0.862\n",
      "4\n",
      "72\n",
      "0.984\n",
      "5\n",
      "55\n",
      "0.847\n",
      "6\n",
      "47\n",
      "0.934\n",
      "7\n",
      "37\n",
      "0.782\n",
      "12\n",
      "41\n",
      "0.796\n",
      "13\n",
      "50\n",
      "0.938\n",
      "14\n",
      "56\n",
      "0.955\n",
      "19\n",
      "59\n",
      "0.87\n"
     ]
    }
   ],
   "source": [
    "idx = [(1, 0), (4, 1), (5, 2), (6, 3), (7, 4), (12, 5), (13, 6), (14, 7), (19, 8)]\n",
    "#idx = [(1, 0)]\n",
    "for z, c in idx:\n",
    "    print(z)\n",
    "    temp_dict = pickle.load(open(r'label' + str(z) + '\\out2.p', 'rb'))\n",
    "    temp_data = pickle.load(open(r'label' + str(z) + '\\out1.p', 'rb'))\n",
    "    length = 0\n",
    "\n",
    "    dict = {}\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    dict3 = {}\n",
    "\n",
    "    for xy in temp_dict:\n",
    "        dict[length] = xy\n",
    "        dict1[xy] = length\n",
    "        length +=1\n",
    "\n",
    "    length = 0\n",
    "    for xy in temp_data:\n",
    "        dict2[length] = xy\n",
    "        dict3[xy] = length\n",
    "        length += 1\n",
    "        \n",
    "    data_set = pickle.load(open(r'label' + str(z) + '\\goal_set.p', 'rb'))\n",
    "    data = data_set['train'] + data_set['test'] + data_set['validate']\n",
    "    count1 = 0\n",
    "    \n",
    "    for xy in data:\n",
    "        count1 += 1\n",
    "    X = np.zeros(shape=(count1, temp_dict[\"Total Symptom\"]), dtype=np.uint8)\n",
    "    y = np.zeros(shape=(1, count1), dtype=np.uint8)\n",
    "    y = y.flatten()\n",
    "    count1 = 0\n",
    "    \n",
    "    \n",
    "    for xy in data:\n",
    "        for xx in xy['goal']['explicit_inform_slots']:\n",
    "            X[count1][dict1[xx]] = 1\n",
    "        for xx in xy['goal']['implicit_inform_slots']:\n",
    "            X[count1][dict1[xx]] = 1\n",
    "        y[count1] = dict3[xy['disease_tag']]\n",
    "        count1 += 1\n",
    "    \n",
    "    #model = ExtraTreesClassifier(n_estimators = 10)\n",
    "    #model.fit(X_train, y_train)\n",
    "    #a = model.feature_importances_\n",
    "    tot = int(temp_dict[\"Total Symptom\"])\n",
    "    tot = int((80*tot + 99)/100)\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k = tot)\n",
    "    print(tot)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    X = bestfeatures.transform(X)\n",
    "    dfscores = fit.scores_\n",
    "    #print(dfscores)\n",
    "    l = []\n",
    "    timer = 0\n",
    "    for i in dfscores:\n",
    "        l.append((i, dict[timer]))\n",
    "        timer += 1\n",
    "    l.sort()\n",
    "    res = {}\n",
    "    for i, j in l:\n",
    "        res[j] = float(i)\n",
    "    pickle.dump(obj = res, file = open(r'label' + str(z) + '\\out3.p', 'wb'), protocol = 2)\n",
    "    l.reverse()\n",
    "    r = []\n",
    "    res = {}\n",
    "    for i in range (0, tot):\n",
    "        r.append(l[i])\n",
    "    res = {}\n",
    "    timer = 0\n",
    "    for i, j in r:\n",
    "        res[j] = timer\n",
    "        timer += 1\n",
    "    pickle.dump(obj = res, file = open(r'label' + str(z) + '\\out4.p', 'wb'), protocol = 2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    classifier = LogisticRegression(solver='liblinear', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "listed-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [(1, 0), (4, 1), (5, 2), (6, 3), (7, 4), (12, 5), (13, 6), (14, 7), (19, 8)]\n",
    "x = []\n",
    "for z, c in idx:\n",
    "    temp_dict = pickle.load(open(r'label' + str(z) + '\\out2.p', 'rb'))\n",
    "    temp_data = pickle.load(open(r'label' + str(z) + '\\out1.p', 'rb'))\n",
    "    length = 0\n",
    "\n",
    "    dict0 = {}\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    dict3 = {}\n",
    "\n",
    "    for xy in temp_dict:\n",
    "        dict0[length] = xy\n",
    "        dict1[xy] = length\n",
    "        length += 1\n",
    "    length = 0\n",
    "    for xy in temp_data:\n",
    "        dict2[length] = xy\n",
    "        dict3[xy] = length\n",
    "        length += 1\n",
    "        \n",
    "    #data_set = pickle.load(open(r'label' + str(z) + '\\goal_set.p', 'rb'))\n",
    "    #data = data_set['train'] + data_set['test'] + data_set['validate']\n",
    "    X = np.zeros(shape=(length, temp_dict[\"Total Symptom\"]), dtype=np.uint8)\n",
    "    \n",
    "    for xy in temp_data:\n",
    "        for xx in temp_data[xy]['symptom']:\n",
    "            X[dict3[xy]][dict1[xx]] = 1\n",
    "    \n",
    "    l = {}\n",
    "    len = 0\n",
    "    \n",
    "    for xx in range(0, temp_dict[\"Total Symptom\"]):\n",
    "        cur = 0\n",
    "        r = {}\n",
    "        for yy in range(0, length):\n",
    "            if X[yy][xx] == 1:\n",
    "                r[dict2[yy]] = cur\n",
    "                cur += 1\n",
    "        l[dict0[xx]] = r\n",
    "    \n",
    "    pickle.dump(obj = l, file = open(r'label' + str(z) + '\\out5.p', 'wb'), protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-entrance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
